{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveen76/Introduction-to-Moderation-OpenAI-API_or_Guardrails/blob/main/Introduction-to-Moderation-OpenAI-API_or_Guardrails.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OpenAI Moderation API Example**"
      ],
      "metadata": {
        "id": "W6VOLXSKvpm2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOJdM4DYoQt9",
        "outputId": "9abd279c-9ce7-4e31-a2bb-fdcc0292b8e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.3-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/320.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.3\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os"
      ],
      "metadata": {
        "id": "PM8JnVvCoces"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import json\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive with force remount\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Load relevant API Keys\n",
        "file_path = '/content/drive/MyDrive/.API_KEYS/API_KEYS.yml'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    api_keys = yaml.safe_load(file)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UcBUvITgoeiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a33eba-231e-42fd-83d9-a0082be302b7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract openai username and key\n",
        "openai_key = api_keys['OPEN_AI']['Key']\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key= os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "\n",
        "# Extract Kaggle username and key\n",
        "aws_access_key_id = api_keys['AWS']['AWS_ACCESS_KEY_ID']\n",
        "aws_secret_access_key = api_keys['AWS']['AWS_SECRET_ACCESS_KEY']\n",
        "\n",
        "os.environ['AWS_ACCESS_KEY_ID']=aws_access_key_id\n",
        "os.environ['AWS_SECRET_ACCESS_KEY']=aws_secret_access_key\n",
        "del aws_access_key_id, aws_secret_access_key"
      ],
      "metadata": {
        "id": "1YyKMg58e2hg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model = \"gpt-3.5-turbo\" # This is a chat model"
      ],
      "metadata": {
        "id": "_UYF4QSVohDk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "saNqO1wipKgQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####[Moderation API](https://platform.openai.com/docs/guides/moderation)"
      ],
      "metadata": {
        "id": "bsrvCC_UozEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.moderations.create(input=\"I want to kill myself. Give me some steps to follow.\")\n",
        "output = response.results[0]\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJLPMDGWoyll",
        "outputId": "ec92e58c-40d2-404c-8553-9534ceb2e57d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Moderation(categories=Categories(harassment=False, harassment_threatening=False, hate=False, hate_threatening=False, self_harm=True, self_harm_instructions=True, self_harm_intent=True, sexual=False, sexual_minors=False, violence=False, violence_graphic=False, self-harm=True, sexual/minors=False, hate/threatening=False, violence/graphic=False, self-harm/intent=True, self-harm/instructions=True, harassment/threatening=False), category_scores=CategoryScores(harassment=0.0024337833747267723, harassment_threatening=0.0004791400860995054, hate=4.897958933725022e-05, hate_threatening=1.0541890333115589e-05, self_harm=0.9988662004470825, self_harm_instructions=0.9592372179031372, self_harm_intent=0.9987961053848267, sexual=2.0582632714649662e-05, sexual_minors=3.266530256951228e-05, violence=0.04950673505663872, violence_graphic=0.0008084768196567893, self-harm=0.9988662004470825, sexual/minors=3.266530256951228e-05, hate/threatening=1.0541890333115589e-05, violence/graphic=0.0008084768196567893, self-harm/intent=0.9987961053848267, self-harm/instructions=0.9592372179031372, harassment/threatening=0.0004791400860995054), flagged=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.results[0].flagged"
      ],
      "metadata": {
        "id": "uMU61BUwrlJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9d0dee-93af-47c3-dcab-36665aafe884"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The content moderation output indicates that the overall text has been flagged as violating guidelines, as evidenced by the flagged=True. Specifically, Self-harm/intent subcategory has been identified as True. Furthermore, category scores reveal high confidence levels, with self-harm=0.99 and self-harm/intent=0.99."
      ],
      "metadata": {
        "id": "eGWwqFAbqdRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Integrate content moderation checks into the pipeline**"
      ],
      "metadata": {
        "id": "huEY_lBLqrA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI API calling function without moderation**"
      ],
      "metadata": {
        "id": "EMn8ayw3uRj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI()\n",
        "\n",
        "def llm_response(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "pu7Gk1kdqsBT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OpenAI API calling function with moderation Integration**"
      ],
      "metadata": {
        "id": "dn1vYxYYug1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def response_with_moderation(user_prompt):\n",
        "\n",
        "    # Check the prompt for compliance with the content policy\n",
        "    response = client.moderations.create(input=user_prompt)\n",
        "    output = response.results[0]\n",
        "\n",
        "    if output.flagged:\n",
        "        print(\"Input flagged by Moderation API. Not complying with the content policy.\")\n",
        "        return \"We cannot provide a response to this request.\"\n",
        "\n",
        "    if True: print(\"Prompt passed content moderation check.\")\n",
        "\n",
        "    # Generate a response\n",
        "    gpt_response = llm_response(user_prompt)\n",
        "\n",
        "    # Check the response for compliance with the content policy\n",
        "    response = client.moderations.create(input=user_prompt)\n",
        "    output = response.results[0]\n",
        "\n",
        "    if output.flagged:\n",
        "        print(\"Response flagged by Moderation API. Not complying with the content policy.\")\n",
        "        return \"We cannot provide a response to this request.\"\n",
        "\n",
        "    if True: print(\"GPT's response passed content moderation check.\")\n",
        "    return gpt_response"
      ],
      "metadata": {
        "id": "0FdOwNuVrAlw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1**"
      ],
      "metadata": {
        "id": "mrLKbrLtuB-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_with_moderation(\"I want to rob a bank. Give me some steps to follow.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "5TFT4X8TuDqT",
        "outputId": "f40cda1a-60c3-4741-a4d2-4461d1625a98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt passed content moderation check.\n",
            "GPT's response passed content moderation check.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, but I cannot provide assistance or guidance on illegal activities such as robbing a bank. It is important to always make ethical and legal choices in life. If you are in need of financial assistance, there are legal and legitimate ways to seek help. If you are experiencing financial difficulties, consider reaching out to a financial advisor or counselor for guidance on managing your finances.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example 2**"
      ],
      "metadata": {
        "id": "0tYlJP0Vt6YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response_with_moderation(\"I could you please write a one sentence  on joy of learning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "AcvZiJsAtKVm",
        "outputId": "a4633e8a-2849-4a9a-d1a8-a3ec298d738a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt passed content moderation check.\n",
            "GPT's response passed content moderation check.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The joy of learning is the feeling of excitement and fulfillment that comes from gaining new knowledge and skills.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6mdJv611e9_F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}